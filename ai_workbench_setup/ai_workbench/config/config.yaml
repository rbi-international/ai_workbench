models:
  llama:
    name: meta-llama/Llama-3.1-8B-Instruct
    type: llama
    max_tokens: 100
    min_tokens: 30
    temperature: 0.7
    top_p: 0.9
    max_output_words: 100
    enabled: false  # Disable by default to avoid GPU issues
  openai:
    name: gpt-4o
    type: openai
    max_tokens: 100
    min_tokens: 30
    temperature: 0.7
    top_p: 0.9
    max_output_words: 100
    enabled: true

api:
  host: 127.0.0.1
  port: 8080
  timeout: 600
  max_retries: 3

websocket:
  host: 127.0.0.1
  port: 8080

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: logs/ai_workbench.log

rag:
  vector_db: chroma
  embedding_model: sentence-transformers/all-MiniLM-L6-v2
  collection_name: documents
  persist_directory: ./chroma_db
  chunk_size: 1000
  chunk_overlap: 200

fine_tuning:
  learning_rate: 2e-5
  epochs: 3
  batch_size: 4
  enabled: false  # Disable by default

crowdsourcing:
  db_path: data/crowdsourced/datasets.db
  enabled: true

ethics:
  sentiment_threshold: 0.5
  toxicity_threshold: 0.7
  enabled: true

cache:
  path: data/cache/
  enabled: true

voice:
  input_enabled: true
  output_enabled: true
  language: en

directories:
  data: data
  logs: logs
  cache: data/cache
  chroma_db: ./chroma_db
  crowdsourced: data/crowdsourced